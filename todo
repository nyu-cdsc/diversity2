- working config/runner
  - finally need to separate object instantiation from the config
    - Param objects for instance will have response objects, but in the config they won't have 'used' properties on them
    - just make it optional, still separate. make the object _create_ functions in stimuliservice for the generator
- working event flow
  - response working
    - params give us response object
    - we set switch of 'used' to true whenever one checked and send the entire object up to parent
      - rather than just sending the specific response
    - FOR NOW, just replace that single object of each type that will later be marked as the response type
    - or the values-carrying type. each stimuli has one of these? it's meeting an interface or just a role
    - at the end of it, could just have a marker of 'responder'

- get conditional choices working through generator and back

RESPONSES:
  'payload' which for now just includes the entire object, and it will have an 'action' which tells the generator
    what to do with it

RESPONDERS:
  pulled into the stimuli components if they have anything that is a StimuliResponse type in their parameters (scan? label?)
    else, just fire the doneEvent() when finished, after a parameter-set delay, etc - or the action/frame itself can receive the click..
      or it just defaults to a conditional of layering its entire self with a clickable div that fires done()

FRAME:
  its own component, which handles multiple responses/done events from multiple stimuli, and then passes this up to the parent that handles
    the frame/action itself, and iterates to the next one
  parameters to the frame would be the placement of the stimuli, or it would get this from the stimuli config itself - think on it

- yaml
- export
- validation and error handling
- stricter typing, docblocks, docs

flow is as events --
  stimuli -> appComponent/response aggregator/Frame -> <- service (in reverse)
response sent stimuli->parent, it decides what to let through based on Control settings/param/whatever the child tells it

TODO - move all of this into specific sections rather than global


RESPONSE thoughts:
  - two competing ways to handle it
    1. have it be a tiny object/closure that is passed around and has functionality to set/unset its used property via standardized interface call
    2. they're all the same, so pass it through function that simply flips the used property based on received value object
  - what are the advantages/disadvantages of both?
    - smart object
      - passing around object with logic
      - need to instantiate it
      - the parent needs to know how to talk to it
    - dumb object 
      - the parent has to know how to manipulate it
      - could get reducer/whatever from the same package as the object, but that's just breaking it up more

    - is this a fundamental difference between functional and oo?
    - can/is it sensible to pass a smart/encapsulated object down a list of manipulators? a message-based object.

    - actually is it even relevant in this instance? if it's used, then it would just be passed up to the parent already used - the parent
      would not need to do that itself. it would just be passing it along. so how that's set, makes no difference in this case
    - it only came about because a different type of object was being passed up, which was incomplete and would really act as a message to
      manipulate one later on. that just shouldn't be necessary here. 
      - but should we pass the whole thing up to the parent every single time just to accomodate for the case it needs to be re-used?
        - perhaps it could, in the case that the parent, the parameters, supports a message/call that re-integrates this Response
        - ** so essentially, parameters.replace(response) or something - that would do! **
          - and in that case it wouldn't need the whole thing. just the 'key', which in this case is the value
          - so I leave it just as it is, make Parameter smarter.. but then there's the issue that it's an interface and not an
            abstract/base class. so it may be time to change that.
              - is there a better way to do this that is better for modularity? or is inheritance actually correct in this instance.
              - or one interface is implemented by one, another by another.. or this is removed from the parent and done elsewhere..

              - this could be handled by the runner service. it's already got params, and if the params are actually passed back up for it
                to do something with, then it's like a conditional. although in this case it should probably have an additional value that tells
                it what 'action' to do, e.g. 'replace', 'decide', etc - and then we're right back to actions and reducers..

                - ** so yeah, for now put an optional 'action' onto the object **


DEPLOY:
  - query/store GKE/EKS account credentials
  - direct api to GKE/EKS to spin up nodes -- and create buckets - no TF?
    - make new resource, store reference to resource
  - direct api to send over kube pods
  - pull down key for auth
    - look into how packer does it. without that key I can't get into the instance flat-out, as ssh is the only way in/out
    - here it would be an api, can use the same key for both?
    - look into how it's done on kube
    - make sure it's all in gitignore/stored outside the directory
    - could also put a passphrase on it just in case

    - could also store it in bucket accessible by aws/eks lab member accounts
    - or just that lab account, and administrator account

    - if credentials are never stored, but rather requested every time and instance (api) data accessible via aws/eks/oauth account..
      - that could be better. much better
      - the key used for creation could have lab-known passphrase and be on bucket accessible to just their accounts
      - panda and this login should be oauth/sso anyway. even if this is just at shell interface stage
PULL:
  - read reference to resource
  - connect over some api call rather than ssh, use key to get to it
  - .. figure it out
  - could also just store it in bucket that lab members can access
DESTROY:
  - first PULL all data down to local archive
  - reverse of DEPLOY

LOG -- log the ENTIRE sequence, essentially log the Frames that were traversed, the final tree that the participant experienced,
so it is very clear what occurred
  - could literally print tree mapped to responses (would be nifty feature) in addition to logging the Frame they were in, on
    the Response/eventual csv row
  - could make super nice svg render of it (and text - strategy pattern (w/-mac.txt and -pc.txt for newline variance))
    - or just switch that asks for svg or txt.
    - or just output all into the final zip - csv, svg, txt files
  - and that's what is output from export button in the app, too
  - so just the csv, txt and svg renderers on Response service export()





later:
  - this respository should probably be treated as a dependency, and their projects should be nothing other than:
    package.json
    runsheet.yaml
    assets/

    - and then npm run
      - init, test/serve/develop, deploy, pull, destroy, etc.
      - deploy/pull/destroy just forward to the actual toku package.json call, none of that is in this scaffold repo
      - so it checks and runs init etc. first before actually calling those internally
